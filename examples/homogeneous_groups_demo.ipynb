{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homogeneous Groups Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from binary_performance_evaluator import BinaryPerformanceEvaluator\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1. CONFIGURA√á√ïES\n",
    "# --------------------------------------------------\n",
    "FILE_PATH = \"../../datasets/lending_club/accepted_2007_to_2018Q4.csv\"\n",
    "NROWS     = 1_000\n",
    "TARGET_RAW = \"loan_status\"          # coluna original\n",
    "TARGET     = \"target\"               # nome final bin√°rio\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2. LEITURA E CONVERS√ÉO DE TIPOS MISTOS\n",
    "# --------------------------------------------------\n",
    "def read_and_clean_csv_mixed_types(path, nrows=None, verbose=True):\n",
    "    df = pd.read_csv(path, low_memory=False, nrows=nrows)\n",
    "\n",
    "    # identificar colunas com tipos mistos\n",
    "    for col in df.columns:\n",
    "        types = df[col].dropna().map(type).value_counts()\n",
    "        if len(types) > 1 and verbose:\n",
    "            print(f\"[!] '{col}' com m√∫ltiplos tipos: {dict(types)}\")\n",
    "\n",
    "        # tentativa de convers√£o autom√°tica p/ num√©rico\n",
    "        if len(types) > 1:\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "            except Exception:\n",
    "                df[col] = df[col].astype(str)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = read_and_clean_csv_mixed_types(FILE_PATH, nrows=NROWS)\n",
    "\n",
    "# drop de colunas n√£o usadas (caso existam)\n",
    "df.drop(columns=[c for c in [\"member_id\"] if c in df.columns], inplace=True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3. TARGET BIN√ÅRIO\n",
    "# --------------------------------------------------\n",
    "bad_status = [\"Charged Off\", \"Default\", \"Late (31-120 days)\"]\n",
    "df[TARGET] = df[TARGET_RAW].isin(bad_status).astype(int)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4. DATA E ID\n",
    "# --------------------------------------------------\n",
    "df[\"date\"] = pd.to_datetime(df[\"issue_d\"], format=\"%b-%Y\", errors=\"coerce\")\n",
    "df.drop(columns=[\"issue_d\", TARGET_RAW], inplace=True)\n",
    "\n",
    "df.reset_index(drop=False, inplace=True)   # index ‚ûú nova coluna\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5. FEATURES NUM√âRICAS + IMPUTA√á√ÉO\n",
    "# --------------------------------------------------\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.drop([\"id\", TARGET])\n",
    "na_threshold = 0.30\n",
    "valid_cols = numeric_cols[df[numeric_cols].isna().mean() < na_threshold].tolist()\n",
    "valid_cols.remove('index')\n",
    "\n",
    "df[valid_cols] = df[valid_cols].fillna(df[valid_cols].median())\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 6. DATAFRAME FINAL\n",
    "# --------------------------------------------------\n",
    "df_model = df[[\"id\", \"date\", TARGET] + valid_cols].dropna().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95fc4071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# 7. SPLIT TREINO / TESTE\n",
    "# --------------------------------------------------\n",
    "train_idx, test_idx = train_test_split(\n",
    "    df_model.index,\n",
    "    test_size=0.30,\n",
    "    stratify=df_model[TARGET],\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "df_train = df_model.loc[train_idx].copy()\n",
    "df_test  = df_model.loc[test_idx].copy()\n",
    "\n",
    "X_train, y_train = df_train[valid_cols], df_train[TARGET]\n",
    "X_test , y_test  = df_test[valid_cols] , df_test[TARGET]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aafb8662",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JM\\AppData\\Local\\anaconda3\\envs\\ENV_STONE\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning:\n",
      "\n",
      "`use_label_encoder` is deprecated in 1.7.0.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------\n",
    "# 8. MODELOS COM PAR√ÇMETROS APRIMORADOS\n",
    "# --------------------------------------------------\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        solver='lbfgs',       # bom para datasets m√©dios\n",
    "        class_weight='balanced',  # trata desbalanceamento\n",
    "        C=1.0                 # regulariza√ß√£o inversa (quanto menor, mais regularizado)\n",
    "    ),\n",
    "    \n",
    "    \"DecisionTree\": DecisionTreeClassifier(\n",
    "        max_depth=6,          # evita overfitting\n",
    "        min_samples_leaf=50,  # tamanho m√≠nimo das folhas\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    ),\n",
    "\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=300,     \n",
    "        learning_rate=0.05,   \n",
    "        max_depth=4,          \n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        scale_pos_weight=1.0,     # pode ser ajustado com base no desbalanceamento\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "\n",
    "    \"LightGBM\": LGBMClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        num_leaves=15,            # normalmente ‚âà 2^max_depth\n",
    "        min_child_samples=50,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2151921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# 9. LOOP DE TREINO + AVALIA√á√ÉO COM BinaryPerformanceEvaluator\n",
    "# --------------------------------------------------\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîπ  Treinando {name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    evaluator = BinaryPerformanceEvaluator(\n",
    "        model=model,\n",
    "        df_train=df_train,\n",
    "        df_test=df_test,\n",
    "        target_col=TARGET,\n",
    "        id_cols=[\"id\"],\n",
    "        date_col=\"date\",\n",
    "        homogeneous_group=\"auto\",\n",
    "    )\n",
    "\n",
    "    metrics = evaluator.compute_metrics()\n",
    "    results[name] = metrics\n",
    "\n",
    "    radar = evaluator.plot_group_radar()\n",
    "    radar.update_layout(title=f\"Radar ‚Äì {name}\")\n",
    "    radar.show()\n",
    "\n",
    "# (opcional) m√©tricas comparativas\n",
    "#all_metrics = pd.concat(results, names=[\"model\"])\n",
    "#display(all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dbe745",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüöÄ Treinando modelo: {name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    evaluator = BinaryPerformanceEvaluator(\n",
    "        model=model,\n",
    "        df_train=df_train,\n",
    "        df_test=df_test,\n",
    "        target_col=\"target\",\n",
    "        id_cols=[\"id\"],\n",
    "        date_col=\"date\",\n",
    "        homogeneous_group=\"auto\",  # usa Optimal Binning\n",
    "    )\n",
    "\n",
    "    print(f\"üìä Avaliando modelo: {name}\")\n",
    "    metrics_df = evaluator.compute_metrics()\n",
    "    results[name] = metrics_df\n",
    "\n",
    "    radar_fig = evaluator.plot_group_radar()\n",
    "    radar_fig.update_layout(title=f\"Radar ‚Äì {name}\")\n",
    "    radar_fig.show()\n",
    "\n",
    "# Opcional: juntar todas as m√©tricas em um DataFrame\n",
    "df_results = pd.concat(results, names=[\"modelo\"])\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336f2196",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryPerformanceEvaluator(\n",
    "    model=models.get('LogisticRegression'),\n",
    "    df_train=train,\n",
    "    df_test=test,\n",
    "    target_col=TARGET,\n",
    "    id_cols=['id'],\n",
    "    date_col='date',\n",
    "    homogeneous_group='auto',\n",
    ")\n",
    "evaluator.compute_metrics()\n",
    "\n",
    "radar = evaluator.plot_group_radar()\n",
    "radar.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV_STONE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
