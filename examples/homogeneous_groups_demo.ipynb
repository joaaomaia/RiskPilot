{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homogeneous Groups Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JM\\AppData\\Local\\anaconda3\\envs\\ENV_STONE\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LogisticRegression ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JM\\AppData\\Local\\anaconda3\\envs\\ENV_STONE\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.982     0.996     0.989     49237\n",
      "           1      0.982     0.916     0.948     10763\n",
      "\n",
      "    accuracy                          0.982     60000\n",
      "   macro avg      0.982     0.956     0.969     60000\n",
      "weighted avg      0.982     0.982     0.982     60000\n",
      "\n",
      "\n",
      "=== DecisionTree ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.993     0.993     49237\n",
      "           1      0.969     0.971     0.970     10763\n",
      "\n",
      "    accuracy                          0.989     60000\n",
      "   macro avg      0.981     0.982     0.982     60000\n",
      "weighted avg      0.989     0.989     0.989     60000\n",
      "\n",
      "\n",
      "=== XGBoost ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.999     0.997     49237\n",
      "           1      0.997     0.978     0.987     10763\n",
      "\n",
      "    accuracy                          0.996     60000\n",
      "   macro avg      0.996     0.989     0.992     60000\n",
      "weighted avg      0.996     0.996     0.995     60000\n",
      "\n",
      "\n",
      "=== LightGBM ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\JM\\AppData\\Local\\anaconda3\\envs\\ENV_STONE\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\JM\\AppData\\Local\\anaconda3\\envs\\ENV_STONE\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\JM\\AppData\\Local\\anaconda3\\envs\\ENV_STONE\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\JM\\AppData\\Local\\anaconda3\\envs\\ENV_STONE\\lib\\subprocess.py\", line 1515, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "  File \"c:\\Users\\JM\\AppData\\Local\\anaconda3\\envs\\ENV_STONE\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0x87 in position 103: invalid start byte\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 25113, number of negative: 114887\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10094\n",
      "[LightGBM] [Info] Number of data points in the train set: 140000, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.179379 -> initscore=-1.520563\n",
      "[LightGBM] [Info] Start training from score -1.520563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.999     0.997     49237\n",
      "           1      0.996     0.974     0.985     10763\n",
      "\n",
      "    accuracy                          0.995     60000\n",
      "   macro avg      0.995     0.987     0.991     60000\n",
      "weighted avg      0.995     0.995     0.995     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from binary_performance_evaluator import BinaryPerformanceEvaluator\n",
    "\n",
    "# === CONFIGURA√á√ïES ===\n",
    "FILE_PATH = '../../datasets/lending_club/accepted_2007_to_2018Q4.csv'\n",
    "NROWS = 200_000\n",
    "TARGET = 'target_risco_credito'\n",
    "\n",
    "# === LEITURA E LIMPEZA DE TIPOS MISTOS ===\n",
    "def read_and_clean_csv_mixed_types(path, nrows=None, verbose=True):\n",
    "    df = pd.read_csv(path, low_memory=False, nrows=nrows)\n",
    "    mixed_type_columns = {}\n",
    "    for col in df.columns:\n",
    "        types_in_col = df[col].dropna().apply(type).value_counts()\n",
    "        if len(types_in_col) > 1:\n",
    "            mixed_type_columns[col] = types_in_col\n",
    "            if verbose:\n",
    "                print(f\"[!] Coluna '{col}' com m√∫ltiplos tipos:\\n{types_in_col}\")\n",
    "    for col in mixed_type_columns:\n",
    "        try:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        except:\n",
    "            df[col] = df[col].astype(str)\n",
    "    return df, mixed_type_columns\n",
    "\n",
    "df, _ = read_and_clean_csv_mixed_types(FILE_PATH, nrows=NROWS)\n",
    "\n",
    "# === TARGET BIN√ÅRIO ===\n",
    "status_de_risco = [\"Charged Off\", \"Default\", \"Late (31-120 days)\"]\n",
    "df[TARGET] = df[\"loan_status\"].isin(status_de_risco).astype(int)\n",
    "\n",
    "# === DATAS ===\n",
    "df[\"issue_d\"] = pd.to_datetime(df[\"issue_d\"], format=\"%b-%Y\", errors=\"coerce\")\n",
    "df[\"safra\"] = df[\"issue_d\"].dt.to_period(\"M\")\n",
    "\n",
    "# === FEATURES NUM√âRICAS V√ÅLIDAS ===\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.drop(TARGET, errors='ignore')\n",
    "na_threshold = 0.3\n",
    "valid_numeric_cols = numeric_cols[df[numeric_cols].isna().mean() < na_threshold]\n",
    "df[valid_numeric_cols] = df[valid_numeric_cols].fillna(df[valid_numeric_cols].median())\n",
    "\n",
    "# === PREPARA√á√ÉO DO DATAFRAME PARA AVALIA√á√ÉO ===\n",
    "df_model = df[valid_numeric_cols.tolist() + [\"issue_d\", TARGET]].dropna().copy()\n",
    "df_model.rename(columns={\"issue_d\": \"date\", TARGET: \"target\"}, inplace=True)\n",
    "df_model.reset_index(drop=False, inplace=True)\n",
    "df_model.rename(columns={\"index\": \"id\"}, inplace=True)\n",
    "\n",
    "# === DIVIS√ÉO TREINO/TESTE USANDO √çNDICES ===\n",
    "train_idx, test_idx = train_test_split(\n",
    "    df_model.index,\n",
    "    test_size=0.3,\n",
    "    stratify=df_model[\"target\"],\n",
    "    random_state=42\n",
    ")\n",
    "df_train = df_model.loc[train_idx].copy()\n",
    "df_test = df_model.loc[test_idx].copy()\n",
    "\n",
    "# === FEATURES ===\n",
    "feature_cols = valid_numeric_cols.tolist()\n",
    "X_train = df_train[feature_cols]\n",
    "y_train = df_train[\"target\"]\n",
    "X_test = df_test[feature_cols]\n",
    "y_test = df_test[\"target\"]\n",
    "\n",
    "# === MODELOS ===\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\"),\n",
    "    \"LightGBM\": LGBMClassifier()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüöÄ Treinando modelo: {name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    evaluator = BinaryPerformanceEvaluator(\n",
    "        model=model,\n",
    "        df_train=df_train,\n",
    "        df_test=df_test,\n",
    "        target_col=\"target\",\n",
    "        id_cols=[\"id\"],\n",
    "        date_col=\"date\",\n",
    "        homogeneous_group=\"auto\",  # usa Optimal Binning\n",
    "    )\n",
    "\n",
    "    print(f\"üìä Avaliando modelo: {name}\")\n",
    "    metrics_df = evaluator.compute_metrics()\n",
    "    results[name] = metrics_df\n",
    "\n",
    "    radar_fig = evaluator.plot_group_radar()\n",
    "    radar_fig.update_layout(title=f\"Radar ‚Äì {name}\")\n",
    "    radar_fig.show()\n",
    "\n",
    "# Opcional: juntar todas as m√©tricas em um DataFrame\n",
    "df_results = pd.concat(results, names=[\"modelo\"])\n",
    "display(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dbe745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336f2196",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryPerformanceEvaluator(\n",
    "    model=models.get('LogisticRegression'),\n",
    "    df_train=train,\n",
    "    df_test=test,\n",
    "    target_col=TARGET,\n",
    "    id_cols=['id'],\n",
    "    date_col='date',\n",
    "    homogeneous_group='auto',\n",
    ")\n",
    "evaluator.compute_metrics()\n",
    "\n",
    "radar = evaluator.plot_group_radar()\n",
    "radar.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV_STONE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
